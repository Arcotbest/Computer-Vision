{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet-Complete-Scrtch.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rASrtR981lBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, ReLU\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Add\n",
        "\n",
        "class ResNetV2(object):\n",
        "    \"\"\" Construct a Residual Convolution Network Network V2 \"\"\"\n",
        "    # Meta-parameter: list of groups: number of filters and number of blocks\n",
        "    groups = { 50 : [ (64, 3), (128, 4), (256, 6),  (512, 3) ],           # ResNet50\n",
        "               101: [ (64, 3), (128, 4), (256, 23), (512, 3) ],           # ResNet101\n",
        "               152: [ (64, 3), (128, 8), (256, 36), (512, 3) ]            # ResNet152\n",
        "             }\n",
        "    _model = None\n",
        "    init_weights = 'he_normal'\n",
        "\n",
        "    def __init__(self, n_layers, input_shape=(224, 224, 3), n_classes=1000):\n",
        "        \"\"\" Construct a Residual Convolutional Neural Network V2\n",
        "            n_layers   : number of layers\n",
        "            input_shape: input shape\n",
        "            n_classes  : number of output classes\n",
        "        \"\"\"\n",
        "        if n_layers not in [50, 101, 152]:\n",
        "            raise Exception(\"ResNet: Invalid value for n_layers\")\n",
        "\n",
        "        # The input tensor\n",
        "        inputs = Input(input_shape)\n",
        "\n",
        "        # The stem convolutional group\n",
        "        x = self.stem(inputs)\n",
        "\n",
        "        # The learner\n",
        "        x = self.learner(x, self.groups[n_layers])\n",
        "\n",
        "        # The classifier for 1000 classes\n",
        "        outputs = self.classifier(x, n_classes)\n",
        "\n",
        "        # Instantiate the Model\n",
        "        self._model = Model(inputs, outputs)\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self._model\n",
        "\n",
        "    @model.setter\n",
        "    def model(self, _model):\n",
        "        self._model = _model\n",
        "\n",
        "    def stem(self, inputs):\n",
        "        \"\"\" Construct the Stem Convolutional Group \n",
        "            inputs : the input vector\n",
        "        \"\"\"\n",
        "        # The 224x224 images are zero padded (black - no signal) to be 230x230 images prior to the first convolution\n",
        "        x = ZeroPadding2D(padding=(3, 3))(inputs)\n",
        "    \n",
        "        # First Convolutional layer uses large (coarse) filter\n",
        "        x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', use_bias=False, kernel_initializer=self.init_weights)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "    \n",
        "        # Pooled feature maps will be reduced by 75%\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "        return x\n",
        "\n",
        "    def learner(self, x, groups):\n",
        "        \"\"\" Construct the Learner\n",
        "            x     : input to the learner\n",
        "            groups: list of groups: number of filters and blocks\n",
        "        \"\"\"\n",
        "        # First Residual Block Group (not strided)\n",
        "        n_filters, n_blocks = groups.pop(0)\n",
        "        x = ResNetV2.group(x, n_filters, n_blocks, strides=(1, 1))\n",
        "\n",
        "        # Remaining Residual Block Groups (strided)\n",
        "        for n_filters, n_blocks in groups:\n",
        "            x = ResNetV2.group(x, n_filters, n_blocks)\n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def group(x, n_filters, n_blocks, strides=(2, 2), init_weights=None):\n",
        "        \"\"\" Construct a Residual Group\n",
        "            x         : input into the group\n",
        "            n_filters : number of filters for the group\n",
        "            n_blocks  : number of residual blocks with identity link\n",
        "            strides   : whether the projection block is a strided convolution\n",
        "        \"\"\"\n",
        "        # Double the size of filters to fit the first Residual Group\n",
        "        x = ResNetV2.projection_block(x, n_filters, strides=strides, init_weights=init_weights)\n",
        "\n",
        "        # Identity residual blocks\n",
        "        for _ in range(n_blocks):\n",
        "            x = ResNetV2.identity_block(x, n_filters, init_weights=init_weights)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def identity_block(x, n_filters, init_weights=None):\n",
        "        \"\"\" Construct a Bottleneck Residual Block with Identity Link\n",
        "            x        : input into the block\n",
        "            n_filters: number of filters\n",
        "        \"\"\"\n",
        "        if init_weights is None:\n",
        "            init_weights = ResNetV2.init_weights\n",
        "    \n",
        "        # Save input vector (feature maps) for the identity link\n",
        "        shortcut = x\n",
        "    \n",
        "        ## Construct the 1x1, 3x3, 1x1 convolution block\n",
        "    \n",
        "        # Dimensionality reduction\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(n_filters, (1, 1), strides=(1, 1), use_bias=False, kernel_initializer=init_weights)(x)\n",
        "\n",
        "        # Bottleneck layer\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding=\"same\", use_bias=False, kernel_initializer=init_weights)(x)\n",
        "\n",
        "        # Dimensionality restoration - increase the number of output filters by 4X\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(n_filters * 4, (1, 1), strides=(1, 1), use_bias=False, kernel_initializer=init_weights)(x)\n",
        "\n",
        "        # Add the identity link (input) to the output of the residual block\n",
        "        x = Add()([shortcut, x])\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def projection_block(x, n_filters, strides=(2,2), init_weights=None):\n",
        "        \"\"\" Construct a Bottleneck Residual Block of Convolutions with Projection Shortcut\n",
        "            Increase the number of filters by 4X\n",
        "            x        : input into the block\n",
        "            n_filters: number of filters\n",
        "            strides  : whether the first convolution is strided\n",
        "        \"\"\"\n",
        "        # Construct the projection shortcut\n",
        "        # Increase filters by 4X to match shape when added to output of block\n",
        "        shortcut = BatchNormalization()(x)\n",
        "        shortcut = Conv2D(4 * n_filters, (1, 1), strides=strides, use_bias=False, kernel_initializer='he_normal')(shortcut)\n",
        "\n",
        "        ## Construct the 1x1, 3x3, 1x1 convolution block\n",
        "    \n",
        "        # Dimensionality reduction\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(n_filters, (1, 1), strides=(1,1), use_bias=False, kernel_initializer='he_normal')(x)\n",
        "\n",
        "        # Bottleneck layer\n",
        "        # Feature pooling when strides=(2, 2)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(n_filters, (3, 3), strides=strides, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
        "\n",
        "        # Dimensionality restoration - increase the number of filters by 4X\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(4 * n_filters, (1, 1), strides=(1, 1), use_bias=False, kernel_initializer='he_normal')(x)\n",
        "\n",
        "        # Add the projection shortcut to the output of the residual block\n",
        "        x = Add()([x, shortcut])\n",
        "        return x\n",
        "\n",
        "    def classifier(self, x, n_classes):\n",
        "        \"\"\" Construct the Classifier Group \n",
        "            x         : input to the classifier\n",
        "            n_classes : number of output classes\n",
        "        \"\"\"\n",
        "        # Pool at the end of all the convolutional residual blocks\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "        # Final Dense Outputting Layer for the outputs\n",
        "        outputs = Dense(n_classes, activation='softmax', kernel_initializer=self.init_weights)(x)\n",
        "        return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UQKZPdR3OYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Example\n",
        "resnet = ResNetV2(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ2b040U1yVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make mini-ResNetV1 for CIFAR-10\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "\n",
        "# Stem\n",
        "inputs = Input((32, 32, 3))\n",
        "x = Conv2D(32, (3, 3), strides=1, padding='same', activation='relu')(inputs)\n",
        "\n",
        "# Learner\n",
        "# Residual group: 2 blocks, 128 filters\n",
        "# Residual block with projection, 256 filters\n",
        "# Residual block with identity, 256 filters\n",
        "x = ResNetV2.group(x, 2, 128)\n",
        "x = ResNetV2.projection_block(x, 256)\n",
        "x = ResNetV2.identity_block(x, 256)\n",
        "\n",
        "# Classifier\n",
        "x = Flatten()(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLVLLGSe3-aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='ResNet.png')\n",
        "#SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWFhMPba5a_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = (x_train / 255.0).astype(np.float32)\n",
        "x_test  = (x_test  / 255.0).astype(np.float32)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=64, validation_split=0.1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRvVs4GX-uY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('final_model-Resnet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF1F-EXA-w1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a prediction for a new image.\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# List of names for each CIFAR10 class\n",
        "cifar10_class_names = {\n",
        "    0: \"Plane\",\n",
        "    1: \"Car\",\n",
        "    2: \"Bird\",\n",
        "    3: \"Cat\",\n",
        "    4: \"Deer\",\n",
        "    5: \"Dog\",\n",
        "    6: \"Frog\",\n",
        "    7: \"Horse\",\n",
        "    8: \"Boat\",\n",
        "    9: \"Truck\"\n",
        "}\n",
        "\n",
        "# Load the entire data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "model = load_model('final_model-Resnet.h5')\n",
        "# Load an image file to test, resizing it to 32x32 pixels (as required by this model)\n",
        "img = load_img(\"cat_or_dog_1.jpg\", target_size=(32, 32))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_to_test = img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n",
        "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "\n",
        "# Make a prediction using the model\n",
        "results = model.predict(list_of_images)\n",
        "\n",
        "# Since we are only testing one image, we only need to check the first result\n",
        "single_result = results[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}