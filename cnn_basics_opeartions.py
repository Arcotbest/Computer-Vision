# -*- coding: utf-8 -*-
"""CNN Basics-Opeartions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SAxUHkzLLXgv8Y1lvV_nBMKj30Tucz_n
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# !pip install scikit-image   # Uncomment to install this module
# !pip install matplotlib     # Uncomment to install this module
import tensorflow as tf
import matplotlib
from matplotlib import pyplot as plt
from skimage import io        # Package to simp

# Read the input the image
image = io.imread("bird_pic_by_benjamin_planche.png")

print("Image shape: {}".format(image.shape))
plt.imshow(image, cmap=plt.cm.gray);



"""To feed this image to TensorFlow operations, we will first convert it into a Tensor:"""

image = tf.convert_to_tensor(image, tf.float32, name="input_image");

image

"""As most of the Tensorflow operations are meant for batched images, i.e., of shape $(B, H, W, D)$ we will synthetically expand the dimensions of our image, to turn it into a batch of one single image:"""

image = tf.expand_dims(image, axis=0) # we expand our tensor, adding a dimension at position 0

image

"""Similarly, as our image is grayscale and have only one channel, it currently doesn't explicitely have a 4th depth dimension. We correct that by expanding our tensor again:"""

image = tf.expand_dims(image, axis=-1) # we expand our tensor, adding a dimension at position 0
print("Tensor shape: {}".format(image.shape))

"""## Convolution

we define a $3 \times 3$ filter (or kernel) commonly used to blur images (Gaussian blur):
"""

kernel = tf.constant([[1 / 16, 2 / 16, 1 / 16],
                      [2 / 16, 4 / 16, 2 / 16],
                      [1 / 16, 2 / 16, 1 / 16]], tf.float32, name="gaussian_kernel")

kernel.shape

"""However, the convolution method requires the filter tensor to be of shape $(k, k, D, N)$ (with $k$ the filter size for square ones, and $N$ the number of filters). Though $D = 1$ and $N = 1$ in our case, we still need to reshape our kernel to explicitely express those values:"""



kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)

blurred_image = tf.nn.conv2d(image, kernel, strides=[1, 1, 1, 1], padding="SAME")
blurred_image.shape

blurred_res = blurred_image.numpy()
# We "unbatch" our result by selecting the first (and only) image; we also remove the depth dimension:
blurred_res = blurred_res[0, ..., 0]

plt.imshow(blurred_res, cmap=plt.cm.gray)

kernel = tf.constant([[-1, -1, -1],
                      [-1,  8, -1],
                      [-1, -1, -1]], tf.float32, name="edge_kernel")
kernel = tf.expand_dims(tf.expand_dims(kernel, axis=-1), axis=-1)

edge_image = tf.nn.conv2d(image, kernel, strides=[1, 2, 2, 1], padding="SAME")
edge_res = edge_image.numpy()[0, ..., 0]
plt.imshow(edge_res, cmap=plt.cm.gray)

edge_image.shape

"""If you look closely, the image has a white border. This is caused by the zero-padding (since we chose padding "SAME"), detected as a contour by the kernel. Indeed, it disappears if we don't pad the image:"""

edge_image = tf.nn.conv2d(image, kernel, strides=[1, 2, 2, 1], padding="VALID")
edge_res = edge_image.numpy()[0, ..., 0]
plt.imshow(edge_res, cmap=plt.cm.gray)

edge_image.shape

"""##Pooling
For max-pooling and average-pooling, the values in each window are aggregated into a single output, applying respectively the max or averaging operation.
"""

avg_pooled_image = tf.nn.avg_pool(image, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")
avg_res = avg_pooled_image.numpy()[0, ..., 0]
plt.imshow(avg_res, cmap=plt.cm.gray)

avg_pooled_image.shape

"""With these hyper-parameters, the average pooling divided each dimension of the input image by 2.

Now performing the max-pooling:
"""

max_pooled_image = tf.nn.max_pool(image, ksize=[1, 10, 10, 1],strides=[1, 1, 1, 1],padding="VALID")
max_res = max_pooled_image.numpy()[0, ..., 0]
plt.imshow(max_res, cmap=plt.cm.gray)

max_pooled_image.shape